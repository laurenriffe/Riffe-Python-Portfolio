{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, ensure that spaCy and pandas are installed in your Python environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset\n",
    "\n",
    "Now we need to load the stocks-1.tsv file into a pandas DataFrame. Since the file is in .tsv format, we'll use pd.read_csv() with sep='\\t' to load it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Industry</th>\n",
       "      <th>MarketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>53.65B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa</td>\n",
       "      <td>Metals &amp; Mining</td>\n",
       "      <td>9.25B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>Ares Acquisition</td>\n",
       "      <td>Shell Companies</td>\n",
       "      <td>1.22B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACG</td>\n",
       "      <td>ATA Creativity Global</td>\n",
       "      <td>Diversified Consumer Services</td>\n",
       "      <td>90.35M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AADI</td>\n",
       "      <td>Aadi Bioscience</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>104.85M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol            CompanyName                        Industry MarketCap\n",
       "0      A   Agilent Technologies  Life Sciences Tools & Services    53.65B\n",
       "1     AA                  Alcoa                 Metals & Mining     9.25B\n",
       "2    AAC       Ares Acquisition                 Shell Companies     1.22B\n",
       "3   AACG  ATA Creativity Global   Diversified Consumer Services    90.35M\n",
       "4   AADI        Aadi Bioscience                 Pharmaceuticals   104.85M"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (adjust the path as needed)\n",
    "df = pd.read_csv('stocks-1.tsv', sep='\\t')\n",
    "\n",
    "# Display the first few rows of the DataFrame to examine the structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Data for Patterns\n",
    "\n",
    "Assume the columns for company names and stock symbols are Company and Symbol respectively. We’ll extract the unique values from these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Names: ['Agilent Technologies' 'Alcoa' 'Ares Acquisition' 'ATA Creativity Global'\n",
      " 'Aadi Bioscience' 'Arlington Asset Investment' 'American Airlines'\n",
      " 'Altisource Asset Management' 'Atlantic American' \"The Aaron's Company\"]\n"
     ]
    }
   ],
   "source": [
    "# Extract unique company names from the 'CompanyName' column\n",
    "company_names = df['CompanyName'].unique()\n",
    "\n",
    "# Display the first few company names to verify\n",
    "print(\"Company Names:\", company_names[:10])\n",
    "\n",
    "# Create patterns for the company names\n",
    "patterns = [{\"label\": \"COMPANY\", \"pattern\": company} for company in company_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create an EntityRuler\n",
    "\n",
    "Now, let's use the spaCy model to create the EntityRuler and add it to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x176f4dd90>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x1773214f0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x176de57e0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x1773a8690>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x17731b850>), ('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x1770cff50>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x17720c2e0>)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add the EntityRuler to the pipeline before the 'ner' component\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "# Add the patterns for the company names to the EntityRuler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# Verify the updated pipeline components\n",
    "print(nlp.pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the EntityRuler\n",
    "\n",
    "We’ll test the EntityRuler using the sample texts provided in the assignment. First, let’s define the paragraphs and process them with the updated nlp pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Helmerich & Payne, Label: COMPANY\n",
      "Entity: HP, Label: ORG\n",
      "Entity: 1.5%, Label: PERCENT\n",
      "Entity: the Energy Equipment & Services, Label: ORG\n",
      "Entity: Check-Cap, Label: COMPANY\n",
      "Entity: 2.3%, Label: PERCENT\n",
      "Entity: Aemetis, Label: COMPANY\n",
      "Entity: 1.5%, Label: PERCENT\n",
      "Entity: the Oil, Gas & Consumable Fuels, Label: ORG\n",
      "Entity: Ferro Corporation, Label: COMPANY\n",
      "Entity: FOE, Label: ORG\n",
      "Entity: 2.3%, Label: PERCENT\n"
     ]
    }
   ],
   "source": [
    "# Sample text with company names\n",
    "text = \"\"\"\n",
    "Helmerich & Payne (HP) saw its stock rise by 1.5%, fueled by optimistic forecasts in the Energy Equipment & Services sector. \n",
    "In contrast, Check-Cap (CHEK) faced a decline of 2.3% following its announcement of increased costs related to supply chain disruptions.\n",
    "\"\"\"\n",
    "\n",
    "# Process the text with the updated spaCy pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "# Display the recognized entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n",
    "\n",
    "# Another sample text with company names\n",
    "text2 = \"\"\"\n",
    "Aemetis (AMTX) saw its stock rise by 1.5%, fueled by optimistic forecasts in the Oil, Gas & Consumable Fuels sector.\n",
    "Meanwhile, Ferro Corporation (FOE) faced a decline of 2.3% following its announcement of increased costs.\n",
    "\"\"\"\n",
    "\n",
    "# Process the second sample text\n",
    "doc2 = nlp(text2)\n",
    "\n",
    "# Display the recognized entities and their labels\n",
    "for ent in doc2.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Testing and Reprocessing\n",
    "\n",
    "Finally, after running the EntityRuler, you should test it on other text inputs to ensure it consistently recognizes company names and stock symbols. Additionally, reprocess the DataFrame to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Aemetis, Label: COMPANY\n",
      "Entity: 1.5%, Label: PERCENT\n",
      "Entity: the Oil, Gas & Consumable Fuels, Label: ORG\n",
      "Entity: Ferro Corporation, Label: COMPANY\n",
      "Entity: FOE, Label: ORG\n",
      "Entity: 2.3%, Label: PERCENT\n"
     ]
    }
   ],
   "source": [
    "# Display all entities from the second sample text\n",
    "for ent in doc2.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
